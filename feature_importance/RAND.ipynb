{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14c0895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ellio\\AppData\\Local\\Programs\\Python\\Python312\\python.exe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ellio\\AppData\\Local\\Temp\\ipykernel_22592\\113384497.py:5: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "c:\\Users\\ellio\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all good\n"
     ]
    }
   ],
   "source": [
    "# RAND Score Clustering Analysis\n",
    "#Imports\n",
    "import sys\n",
    "print(sys.executable)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import umap\n",
    "import hdbscan\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import adjusted_rand_score, rand_score\n",
    "import plotly.express as px\n",
    "print(\"all good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47fb8d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanding: ['a0_band_powers', 'a0_band_ratios', 'a0_spectrogram_features', 'a0_wavelet_energy_features', 'a1_band_powers', 'a1_band_ratios', 'a1_spectrogram_features', 'a1_wavelet_energy_features']\n",
      "Final feature count: 73\n",
      "Scaling complete: (446, 73)\n"
     ]
    }
   ],
   "source": [
    "# Load and scale data\n",
    "import re\n",
    "import ast\n",
    "\n",
    "df = pd.read_csv(\"../data/features_updated.csv\")\n",
    "file_names = df[\"file_name\"]\n",
    "X = df.drop(columns=[\"file_name\"])\n",
    "def safe_parse_dict(s):\n",
    "    \"\"\"Parse dict-like strings safely. Returns {} if parsing fails.\"\"\"\n",
    "    if pd.isna(s):\n",
    "        return {}\n",
    "    s = str(s).strip()\n",
    "    if not s.startswith(\"{\"):\n",
    "        return {}\n",
    "    \n",
    "    # Remove np.float64(...) wrappers -> just the number inside\n",
    "    s = re.sub(r\"np\\.float64\\(([^)]+)\\)\", r\"\\1\", s)\n",
    "    \n",
    "    # Replace 'nan' with None (literal_eval can't parse bare nan)\n",
    "    s = s.replace(\"nan\", \"None\")\n",
    "    \n",
    "    try:\n",
    "        out = ast.literal_eval(s)\n",
    "        return out if isinstance(out, dict) else {}\n",
    "    except Exception:\n",
    "        return {}\n",
    "\n",
    "# Find dict-like columns\n",
    "dict_cols = [c for c in X.columns if X[c].astype(str).str.strip().str.startswith(\"{\").any()]\n",
    "print(\"Expanding:\", dict_cols)\n",
    "\n",
    "for c in dict_cols:\n",
    "    parsed = X[c].apply(safe_parse_dict)\n",
    "    expanded = pd.json_normalize(parsed).add_prefix(f\"{c}_\")\n",
    "    X = X.drop(columns=[c]).join(expanded)\n",
    "\n",
    "# Convert everything numeric\n",
    "X = X.apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n",
    "\n",
    "print(\"Final feature count:\", X.shape[1])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "print(\"Scaling complete:\", X_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0adb7720",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ellio\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\umap\\umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "#UMAP\n",
    "umap_model = umap.UMAP(\n",
    "    n_neighbors=15,\n",
    "    min_dist=0.1,\n",
    "    n_components=2,\n",
    "    metric=\"euclidean\",\n",
    "    random_state=42\n",
    ")\n",
    "X_umap = umap_model.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "632ea4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters: 2\n",
      "Noise points: 0 / 446\n"
     ]
    }
   ],
   "source": [
    "#HDBSCAN tuned for 2 clusters\n",
    "# need to tune min_cluster_size and min_samples until we get exactly 2 clusters\n",
    "clusterer = hdbscan.HDBSCAN(\n",
    "    min_cluster_size=50, # increase to merge smaller clusters into 1\n",
    "    min_samples=10,\n",
    "    metric=\"euclidean\"\n",
    ")\n",
    "predicted_labels = clusterer.fit_predict(X_umap)\n",
    "n_clusters = len(set(predicted_labels) - {-1})\n",
    "n_noise = (predicted_labels == -1).sum()\n",
    "print(f\"Number of clusters: {n_clusters}\")\n",
    "print(f\"Noise points: {n_noise} / {len(predicted_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c4cb50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactive plot saved to ..\\visuals\\cluster_plot.html — open in a browser to use click functionality.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ellio\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\plotly\\express\\_core.py:2065: FutureWarning:\n",
      "\n",
      "When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Visualization of clusters\n",
    "plot_df = pd.DataFrame({\n",
    "    \"UMAP-1\": X_umap[:, 0],\n",
    "    \"UMAP-2\": X_umap[:, 1],\n",
    "    \"cluster\": predicted_labels.astype(str),\n",
    "    \"file_name\": file_names.values\n",
    "})\n",
    "fig = px.scatter(plot_df, x=\"UMAP-1\", y=\"UMAP-2\", color=\"cluster\",\n",
    "                 hover_data=[\"file_name\"], title=\"UMAP + HDBSCAN (2-cluster target)\")\n",
    "fig.update_layout(width=800, height=600)\n",
    "\n",
    "html_template = \"\"\"\n",
    "<html>\n",
    "<head>\n",
    "    <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>\n",
    "</head>\n",
    "<body>\n",
    "    <div id=\"plot\"></div>\n",
    "    <div id=\"image-container\" style=\"margin-top: 20px; text-align: center;\">\n",
    "        <p id=\"image-label\" style=\"font-family: Arial; color: #555;\"></p>\n",
    "        <img id=\"clicked-image\" src=\"\" style=\"display:none; max-width: 900px; border: 1px solid #ccc; border-radius: 6px;\"/>\n",
    "        <p id=\"no-image-msg\" style=\"font-family: Arial; color: #999; display:none;\">No plot found for this file.</p>\n",
    "    </div>\n",
    "    <script>\n",
    "        var plotData = PLOTLY_JSON;\n",
    "        Plotly.newPlot('plot', plotData.data, plotData.layout);\n",
    "\n",
    "        document.getElementById('plot').on('plotly_click', function(data) {\n",
    "            var point = data.points[0];\n",
    "            var fileName = point.customdata[0];\n",
    "            var baseName = fileName.replace(/\\\\.csv$/, '');\n",
    "            var imgPath = '../visuals/boiling_plots/' + baseName + '.png';\n",
    "\n",
    "            var img = document.getElementById('clicked-image');\n",
    "            var label = document.getElementById('image-label');\n",
    "            var noMsg = document.getElementById('no-image-msg');\n",
    "\n",
    "            img.src = imgPath;\n",
    "            img.style.display = 'block';\n",
    "            noMsg.style.display = 'none';\n",
    "            label.textContent = 'File: ' + fileName;\n",
    "\n",
    "            img.onerror = function() {\n",
    "                img.style.display = 'none';\n",
    "                noMsg.style.display = 'block';\n",
    "                label.textContent = 'File: ' + fileName;\n",
    "            };\n",
    "        });\n",
    "    </script>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "import plotly.io as pio\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "fig_json = json.loads(pio.to_json(fig))\n",
    "html_content = html_template.replace(\"PLOTLY_JSON\", json.dumps(fig_json))\n",
    "\n",
    "output_path = Path(\"../visuals/cluster_plot.html\")\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "with open(output_path, \"w\") as f:\n",
    "    f.write(html_content)\n",
    "\n",
    "print(f\"Interactive plot saved to {output_path} — open in a browser to use click functionality.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c320f887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled samples: 283\n",
      "  Rhythmic (1):     177\n",
      "  Non-rhythmic (0): 106\n"
     ]
    }
   ],
   "source": [
    "# Load ground truth from Excel and map to binary\n",
    "\n",
    "# Expects: column A = file name, column B = category number (1-8)\n",
    "gt_df = pd.read_excel(\"../data/Labeling.xlsx\")  \n",
    "\n",
    "# Drop unlabeled rows\n",
    "gt_df = gt_df.dropna(subset=[\"Label\"])\n",
    "gt_df[\"Label\"] = gt_df[\"Label\"].astype(int)\n",
    "\n",
    "# Add \"MATLAB \" prefix to match features.csv file_name format\n",
    "gt_df[\"file_name\"] = \"MATLAB \" + gt_df[\"File\"]\n",
    "\n",
    "# Category mapping:\n",
    "# 1 = Single Rhythmic        → rhythmic\n",
    "# 2 = Double Rhythmic         → rhythmic\n",
    "# 3 = Random                  → non-rhythmic\n",
    "# 4 = Rhythmic with Climax    → rhythmic\n",
    "# 5 = Noise                   → non-rhythmic\n",
    "# 6 = 1 Rhythmic with Random  → rhythmic\n",
    "# 7 = Triple Rhythmic         → rhythmic\n",
    "# 8 = Transition              → EXCLUDE (ambiguous)\n",
    "\n",
    "category_names = {\n",
    "    1: \"Single Rhythmic\",\n",
    "    2: \"Double Rhythmic\",\n",
    "    3: \"Random\",\n",
    "    4: \"Rhythmic with Climax\",\n",
    "    5: \"Noise\",\n",
    "    6: \"1 Rhythmic with Random\",\n",
    "    7: \"Triple Rhythmic\",\n",
    "    8: \"Transition\"\n",
    "}\n",
    "\n",
    "rhythmic_ids = [1, 2, 4, 6, 7]\n",
    "non_rhythmic_ids = [3, 5]\n",
    "\n",
    "gt_df[\"ground_truth_binary\"] = gt_df[\"Label\"].apply(\n",
    "    lambda x: 1 if x in rhythmic_ids else (0 if x in non_rhythmic_ids else np.nan)\n",
    ")\n",
    "\n",
    "# Drop Transition (8) samples\n",
    "gt_df = gt_df.dropna(subset=[\"ground_truth_binary\"])\n",
    "gt_df[\"ground_truth_binary\"] = gt_df[\"ground_truth_binary\"].astype(int)\n",
    "\n",
    "print(f\"Labeled samples: {len(gt_df)}\")\n",
    "print(f\"  Rhythmic (1):     {(gt_df['ground_truth_binary'] == 1).sum()}\")\n",
    "print(f\"  Non-rhythmic (0): {(gt_df['ground_truth_binary'] == 0).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "75fc90d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples matched: 283 / 446\n",
      "Unmatched (no ground truth or Transition): 163\n",
      "\n",
      "RAND Index:          0.7316\n",
      "Adjusted RAND Index: 0.4566\n"
     ]
    }
   ],
   "source": [
    "#RAND calculation\n",
    "pred_df = pd.DataFrame({\n",
    "    \"file_name\": file_names,\n",
    "    \"predicted_cluster\": predicted_labels\n",
    "})\n",
    "\n",
    "merged = pd.merge(pred_df, gt_df[[\"file_name\", \"ground_truth_binary\"]], on=\"file_name\", how=\"inner\")\n",
    "\n",
    "# Optional: also drop HDBSCAN noise points (-1)\n",
    "# merged = merged[merged[\"predicted_cluster\"] != -1]\n",
    "\n",
    "print(f\"\\nSamples matched: {len(merged)} / {len(file_names)}\")\n",
    "print(f\"Unmatched (no ground truth or Transition): {len(file_names) - len(merged)}\")\n",
    "\n",
    "ri = rand_score(merged[\"ground_truth_binary\"], merged[\"predicted_cluster\"])\n",
    "ari = adjusted_rand_score(merged[\"ground_truth_binary\"], merged[\"predicted_cluster\"])\n",
    "\n",
    "print(f\"\\nRAND Index:          {ri:.4f}\")\n",
    "print(f\"Adjusted RAND Index: {ari:.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "898b11d9",
   "metadata": {},
   "source": [
    "The Rand Index (0.73) means that about 73% of all possible pairs of samples were grouped consistently between the unsupervised clustering results and the labeled boiling regimes.\n",
    "**The Rand Index doesn't account for agreement that could occur simply by chance\n",
    "The ARI (0.4566) means that a moderate level of agreement between the unsupervised HDBSCAN clusters and the labeled regimes\n",
    "    -An ARI near 0 would indicate random clustering\n",
    "    -An ARI near 1 would indicate near-perfect agreement."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
